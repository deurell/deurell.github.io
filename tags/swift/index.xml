<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Swift on Deurell Labs</title>
    <link>https://deurell.github.io/tags/swift/</link>
    <description>Recent content in Swift on Deurell Labs</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 10 Feb 2023 10:54:06 +0100</lastBuildDate><atom:link href="https://deurell.github.io/tags/swift/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>RealityKit &lt;3 PencilKit</title>
      <link>https://deurell.github.io/posts/pencilkit/</link>
      <pubDate>Fri, 10 Feb 2023 10:54:06 +0100</pubDate>
      
      <guid>https://deurell.github.io/posts/pencilkit/</guid>
      <description>I had this idea of creating a collaborative AR experience where friends could draw and create art together. I made a small prototype just to play with the format and how it would feel on an iOS device while learning to combine RealityKit and the pretty amazing PencilKit. At this point it mostly serves as a demo of how to integrate RealityKit and PencilKit in a nice way but who knows what will happen in the future.</description>
    </item>
    
    <item>
      <title>RoomPlan using SwiftUI</title>
      <link>https://deurell.github.io/posts/roomplan-swiftui/</link>
      <pubDate>Wed, 08 Feb 2023 10:05:04 +0100</pubDate>
      
      <guid>https://deurell.github.io/posts/roomplan-swiftui/</guid>
      <description>I spent almost a year working with VR/AR for a pretty big game company. They make some great games, mostly in Unity and for the Oculus Quest range of headsets. Some of the games needed to mark out the surrounding play area and obstacles manually in order to start playing. Really nice games but that startup process was quite tedious. When I saw the RoomPlan session at WWDC I had this idea to get rid of the manual setup and instead use one of the players iPhones, map out the surrounding area with RoomPlan, sync it with the headset and then anchor it in the game.</description>
    </item>
    
    <item>
      <title>Controlling AR-entities with an iPhone</title>
      <link>https://deurell.github.io/posts/realitykit-interaction/</link>
      <pubDate>Tue, 07 Feb 2023 12:47:16 +0100</pubDate>
      
      <guid>https://deurell.github.io/posts/realitykit-interaction/</guid>
      <description>I once worked on adding support for hands tracking for an existing VR game on the Oculus Quest2. Moving from controllers to just using your hands made me think about interaction design in VR/AR in a new way. The dream scenario would be to just do the same thing as with controllers, but with hands. That would be fast, cheap and fancy, right? Turns out it worked but wasn&amp;rsquo;t very fun, and didn&amp;rsquo;t spark joy.</description>
    </item>
    
    <item>
      <title>Adding Bezier animations to RealityKit</title>
      <link>https://deurell.github.io/posts/bezier-fish/</link>
      <pubDate>Tue, 17 Jan 2023 10:15:35 +0100</pubDate>
      
      <guid>https://deurell.github.io/posts/bezier-fish/</guid>
      <description>I love animation systems. I wrote animation systems for the C64 and Amiga in the 80&amp;rsquo;s and 90&amp;rsquo;s, for fashion designer apps at H&amp;amp;M, for games like Candy Crush and god knows how many more. RealityKit has a nice and user friendly animation system that can handle different linear world space transforms, play model space animations from usdz models and combine them in sequences or groups. RealityKit entities can play an AnimationResource with the playAnimation method and AnimationResources are created from AnimationDefinitions.</description>
    </item>
    
    <item>
      <title>Using the RealityKit AnchorEntity</title>
      <link>https://deurell.github.io/posts/realitykit-anchorentity/</link>
      <pubDate>Fri, 13 Jan 2023 11:15:08 +0100</pubDate>
      
      <guid>https://deurell.github.io/posts/realitykit-anchorentity/</guid>
      <description>We spent last post learning how ARKit anchors work and how they relate to RealityKit entities. In the end we wrote our own RealityKit AnchorEntity based on the results of the ARSessions provided ARAnchors. This is all fine but if we just need a quick anchor we can use the RealityKit provided AnchorEntity.
We start the same way by setting up an ARSession. Requesting horizontal plane detection.
private func setupARSession() { let session = self.</description>
    </item>
    
    <item>
      <title>Realitykit Surface Detection</title>
      <link>https://deurell.github.io/posts/realitykit-surface-detection/</link>
      <pubDate>Tue, 03 Jan 2023 17:23:40 +0100</pubDate>
      
      <guid>https://deurell.github.io/posts/realitykit-surface-detection/</guid>
      <description>I&amp;rsquo;ve spent a lot of time learning and writing code based on RealityKit. I really like the framework. It&amp;rsquo;s nicely written, has a lovely tiny, lightweight ECS implementation and makes writing AR applications and games pretty straightforward. I thought I&amp;rsquo;d write down some things I&amp;rsquo;ve learned in a series of blog posts that might help other AR devs out there in the wild.
The first thing that comes up when writing a new RealityKit app is detecting surfaces in order to anchor virtual objects in the real world.</description>
    </item>
    
  </channel>
</rss>
