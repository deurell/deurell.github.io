<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>RealityKit on Deurell Labs</title>
    <link>https://deurell.github.io/tags/realitykit/</link>
    <description>Recent content in RealityKit on Deurell Labs</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 07 Feb 2023 12:47:16 +0100</lastBuildDate><atom:link href="https://deurell.github.io/tags/realitykit/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Controlling AR-entities with an iPhone</title>
      <link>https://deurell.github.io/posts/realitykit-interaction/</link>
      <pubDate>Tue, 07 Feb 2023 12:47:16 +0100</pubDate>
      
      <guid>https://deurell.github.io/posts/realitykit-interaction/</guid>
      <description>I once worked on adding support for hands tracking for an existing VR game on the Oculus Quest2. Moving from controllers to just using your hands made me think about interaction design in VR/AR in a new way. The dream scenario would be to just do the same thing as with controllers, but with hands. That would be fast, cheap and fancy, right? Turns out it worked but wasn&amp;rsquo;t very fun, and didn&amp;rsquo;t spark joy.</description>
    </item>
    
    <item>
      <title>Adding Bezier animations to RealityKit</title>
      <link>https://deurell.github.io/posts/bezier-fish/</link>
      <pubDate>Tue, 17 Jan 2023 10:15:35 +0100</pubDate>
      
      <guid>https://deurell.github.io/posts/bezier-fish/</guid>
      <description>I love animation systems. I wrote animation systems for the C64 and Amiga in the 80&amp;rsquo;s and 90&amp;rsquo;s, for fashion designer apps at H&amp;amp;M, for games like Candy Crush and god knows how many more. RealityKit has a nice and user friendly animation system that can handle different linear world space transforms, play model space animations from usdz models and combine them in sequences or groups. RealityKit entities can play an AnimationResource with the playAnimation method and AnimationResources are created from AnimationDefinitions.</description>
    </item>
    
    <item>
      <title>Using the RealityKit AnchorEntity</title>
      <link>https://deurell.github.io/posts/realitykit-anchorentity/</link>
      <pubDate>Fri, 13 Jan 2023 11:15:08 +0100</pubDate>
      
      <guid>https://deurell.github.io/posts/realitykit-anchorentity/</guid>
      <description>We spent last post learning how ARKit anchors work and how they relate to RealityKit entities. In the end we wrote our own RealityKit AnchorEntity based on the results of the ARSessions provided ARAnchors. This is all fine but if we just need a quick anchor we can use the RealityKit provided AnchorEntity.
We start the same way by setting up an ARSession. Requesting horizontal plane detection.
private func setupARSession() { let session = self.</description>
    </item>
    
    <item>
      <title>Realitykit Surface Detection</title>
      <link>https://deurell.github.io/posts/realitykit-surface-detection/</link>
      <pubDate>Tue, 03 Jan 2023 17:23:40 +0100</pubDate>
      
      <guid>https://deurell.github.io/posts/realitykit-surface-detection/</guid>
      <description>I&amp;rsquo;ve spent a lot of time learning and writing code based on RealityKit. I really like the framework. It&amp;rsquo;s nicely written, has a lovely tiny, lightweight ECS implementation and makes writing AR applications and games pretty straightforward. I thought I&amp;rsquo;d write down some things I&amp;rsquo;ve learned in a series of blog posts that might help other AR devs out there in the wild.
The first thing that comes up when writing a new RealityKit app is detecting surfaces in order to anchor virtual objects in the real world.</description>
    </item>
    
  </channel>
</rss>
